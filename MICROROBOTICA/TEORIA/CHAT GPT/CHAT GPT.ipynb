{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfa91ff5",
   "metadata": {},
   "source": [
    "## RETI NEURALI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cd978c",
   "metadata": {},
   "source": [
    "## LLM\n",
    "large language model -> modello linguistico o modello linguistico di grandi dimensioni\n",
    "\n",
    "chat gpt è un agente conversazionale -> chat bot, è un'entità con cui si può sostenere una conversazione in forma scritta e parlata\n",
    "\n",
    "i modelli linguistici sono reti neaurali basati sulla tecnologia de Trasformatori: reti neurali adatte a elaborare testo,\n",
    "i trasformatori usati sono reti neurali generative, ossia capaci di generare testo e di comprenderlo\n",
    "\n",
    "tutti i verbi comprendere, creare non è ovvio sulle reti neurali, non è appropriato dire che chat gpt capisce\n",
    "\n",
    "c'è stato un boom dei modelli linguistici, 2 anni fa open ai ha iniziato a svilupparli\n",
    "chat gpt v3 ha compiuto 1 anni a dicembre, molte aziende da li hanno iniziato a creare reti neurali.\n",
    "\n",
    "tante aziende addestrano modelli open source altre no\n",
    "\n",
    "meta crede nell'open source -> modello linguistico lama https://ai.meta.com/llama/, google o open ai è proprietario\n",
    "\n",
    "una rete neurale è caratterizzata da un certo numero di parametri, un parametro è un numero\n",
    "- più è grande la rete più sono grandi questi numeri esempio liama ha 70 biliardi di parametri, il modello più avanzato, tutti posso scaricarli quelli open source e anche modificarli\n",
    "\n",
    "- Liama 2 è addetsrato su 2 trilioni di token, social, libri...\n",
    "\n",
    "### CHAT GPT\n",
    "\n",
    "open ai gpt 3.5 è utilizzabile gratuitamente con chat bot, il 4 con abbonamento\n",
    "\n",
    "chat gpt 3 e 4 sono diverse perchè usano reti neurali differenti, il 3.5 è un puro chat bot, chat gpt 4 è capace di usare strumenti esterni per esempio interpretare immagini, creare immagini, ricercare su internet...\n",
    "\n",
    "google gemini -> non è solo un  chatbot ma è in grado di usare strumenti\n",
    "\n",
    "\n",
    "chat gpt spezza il testo in token, è un autoregressore, ossia genera in base alla parola precedente, \n",
    "- regressione: prevede cosa viene dopo\n",
    "- autoregressione: prevederlo in base a cosa ho prima, è come un pappagallo socastico (casuale)\n",
    "\n",
    "#### COMPRENSIONE DEL TESTO\n",
    "\n",
    "chat gpt capisce cosa gli scriviamo?\n",
    "questi oggetti hanno un'abilità linguistica formale pazzesca, scrive in maniera corretta\n",
    "e possiamo fargli produrre testo con tono e stile che ci piace\n",
    "\n",
    "chat non capisce cosa noi diciamo\n",
    "\n",
    "- gpt 3.5 -> 1,75*10^11 parametri\n",
    "- gpt 4 -> non è noto, si stima 1,75*10^12 parametri\n",
    "- cervello -> collegamenti sono le sinapsi -> 10^14/10^15 sinapsi\n",
    "i modelli linguistici hanno un numero di parametri non distanti dal numero di sinapsi del cervello umani, quindi secondo alcuni formano delle forme di intelligenza vere\n",
    "\n",
    "possono essere intelligenti, ma non è da confondere con la coscienza (provare emozioni, sentimenti...)\n",
    "\n",
    "per aumentare il numero di parametri basta aumentare la potenza di calcolo e aumentare i dati di addestramento\n",
    "\n",
    "\n",
    "#### come agisce chat gpt?\n",
    "##### il nostro cervello\n",
    "ha due modalità di pensiero:\n",
    "- sistema 1: sistema di pensiero 1, ossia quello a \"costo 0\", no energia, no tempo, istintivo, automatico, emotivo, irrazionale\n",
    "- sistema 2: sistema di pensiero 2, per task più complessi\n",
    "\n",
    "chat gpt e i modelli linguistici al momento hanno solo il sistema 1, sono impulsivi, irrazionali, non possono svolgere task complessi in autonomia -> sono irrazionali\n",
    "\n",
    "in certi compiti sono pessimi, esempio quelli matematici\n",
    "\n",
    "### i prompt\n",
    "\n",
    "quando scrivo un testo nella chat di un chat box si chiama prompt, la risposta si chiama output\n",
    "\n",
    "ingegneria dei prompt\n",
    "\n",
    "- OTTIMIZZARE IL PROMPT: quando diamo task complesse chat non riesce a riconoscere la consegna dal testo, si consiglia di delimitare il testo con dei caratteri, esempio: <>\n",
    "\n",
    "dentro una chat lui usa i messaggi precedenti, chat diverse sono svincolate una dall'altra\n",
    "\n",
    "###### in un prompt posso insegnare a chat gpt\n",
    "\n",
    "### elemeti di un prompt\n",
    "un prompt può contenere:\n",
    "- istruzione: istruzione o compito da eseguire\n",
    "- contesto: possono contenere informazioni esterne o contesti aggiuntivi per indirizzare il modello verso risposte più accurate, es: sei un insegnante di informatica, un tredicenne che conosce poco l'italiano...\n",
    "- dati in input: domanda a cui ci interessa trovare una risposta\n",
    "- indicatore dell'output: indica il tipo o il formato dell'output\n",
    "\n",
    "posso usare processi iterativi per migliorare il prompt fino a che non ottengo una risposta che vada bene, devo usare istruzioni precise e chiare, peciso, specifico e in italiano/inglese corretto\n",
    "\n",
    "è un oggetto che non ragiona-> sempre digli cosa fare e cosa non fare\n",
    "\n",
    "- bisogna dare al modello linguistico il TEMPO DI PENSARE, bisgna guidarli per arrivare alla risposta\n",
    "\n",
    "chat gpt non è capace a contare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a4a5ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
